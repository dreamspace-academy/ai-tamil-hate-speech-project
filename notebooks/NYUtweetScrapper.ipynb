{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NYUtweetScrapper.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install requests~=2.23.0 --quiet\n",
        "!pip install folium==0.2.1 --quiet\n",
        "!pip install urllib3 ==1.26.2 --quiet\n",
        "!pip3 install --user --upgrade git+https://github.com/twintproject/twint.git@origin/master#egg=twint\n",
        "!pip install yake"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXeNCdcuXp72",
        "outputId": "4c84ed89-fcd9-4498-e428-2c8d717d207e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |████▊                           | 10 kB 18.9 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 20 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 30 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 40 kB 3.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 51 kB 3.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 61 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 69 kB 3.0 MB/s \n",
            "\u001b[?25h  Building wheel for folium (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: Invalid requirement: '==1.26.2'\u001b[0m\n",
            "Collecting twint\n",
            "  Cloning https://github.com/twintproject/twint.git (to revision origin/master) to /tmp/pip-install-ta93o8cz/twint_92730f1de7f14550ae4affee0ed4d1a7\n",
            "  Running command git clone -q https://github.com/twintproject/twint.git /tmp/pip-install-ta93o8cz/twint_92730f1de7f14550ae4affee0ed4d1a7\n",
            "\u001b[33m  WARNING: Did not find branch or tag 'origin/master', assuming revision or ref.\u001b[0m\n",
            "  Running command git checkout -q origin/master\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 4.3 MB/s \n",
            "\u001b[?25hCollecting aiodns\n",
            "  Downloading aiodns-3.0.0-py3-none-any.whl (5.0 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from twint) (4.6.3)\n",
            "Collecting cchardet\n",
            "  Downloading cchardet-2.1.7-cp37-cp37m-manylinux2010_x86_64.whl (263 kB)\n",
            "\u001b[K     |████████████████████████████████| 263 kB 26.2 MB/s \n",
            "\u001b[?25hCollecting dataclasses\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Collecting elasticsearch\n",
            "  Downloading elasticsearch-8.2.0-py3-none-any.whl (378 kB)\n",
            "\u001b[K     |████████████████████████████████| 378 kB 39.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pysocks in /usr/local/lib/python3.7/dist-packages (from twint) (1.7.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from twint) (1.3.5)\n",
            "Collecting aiohttp_socks\n",
            "  Downloading aiohttp_socks-0.7.1-py3-none-any.whl (9.3 kB)\n",
            "Collecting schedule\n",
            "  Downloading schedule-1.1.0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: geopy in /usr/local/lib/python3.7/dist-packages (from twint) (1.17.0)\n",
            "Collecting fake-useragent\n",
            "  Downloading fake-useragent-0.1.11.tar.gz (13 kB)\n",
            "Collecting googletransx\n",
            "  Downloading googletransx-2.4.2.tar.gz (13 kB)\n",
            "Collecting pycares>=4.0.0\n",
            "  Downloading pycares-4.1.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (291 kB)\n",
            "\u001b[K     |████████████████████████████████| 291 kB 40.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pycares>=4.0.0->aiodns->twint) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.5.0->pycares>=4.0.0->aiodns->twint) (2.21)\n",
            "Collecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 2.9 MB/s \n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 52.4 MB/s \n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 48.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->twint) (2.0.12)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->twint) (21.4.0)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->twint) (4.2.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl<2.0,>=1.0->aiohttp->twint) (2.10)\n",
            "Collecting python-socks[asyncio]<3.0.0,>=2.0.0\n",
            "  Downloading python_socks-2.0.3-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 5.9 MB/s \n",
            "\u001b[?25hCollecting elastic-transport<9,>=8\n",
            "  Downloading elastic_transport-8.1.2-py3-none-any.whl (59 kB)\n",
            "\u001b[K     |████████████████████████████████| 59 kB 6.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from elastic-transport<9,>=8->elasticsearch->twint) (2021.10.8)\n",
            "Collecting urllib3<2,>=1.26.2\n",
            "  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 38.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: geographiclib<2,>=1.49 in /usr/local/lib/python3.7/dist-packages (from geopy->twint) (1.52)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from googletransx->twint) (2.23.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->twint) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas->twint) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->twint) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->twint) (1.15.0)\n",
            "Collecting requests\n",
            "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.8 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: twint, fake-useragent, googletransx\n",
            "  Building wheel for twint (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for twint: filename=twint-2.1.21-py3-none-any.whl size=38871 sha256=039a8c7a92b0f9c3f7ee1b0a7f08181b4cbd4cd9118031062a6fba24051bac45\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-0g3y8tni/wheels/8d/dc/9f/74b4483d5f997036f04aec7f42bd4b3c80f04264920c368068\n",
            "  Building wheel for fake-useragent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fake-useragent: filename=fake_useragent-0.1.11-py3-none-any.whl size=13502 sha256=bf92cb823a5b71e35f43c42c81efd321d3af61fbbfa7a6f9292848a51ea3d2e2\n",
            "  Stored in directory: /root/.cache/pip/wheels/ed/f7/62/50ab6c9a0b5567267ab76a9daa9d06315704209b2c5d032031\n",
            "  Building wheel for googletransx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googletransx: filename=googletransx-2.4.2-py3-none-any.whl size=15968 sha256=33160fcfc27256222260f96c00809c468fb74efde873cb1c28d194111fc02d75\n",
            "  Stored in directory: /root/.cache/pip/wheels/66/d5/b1/31104b338f7fd45aa8f7d22587765db06773b13df48a89735f\n",
            "Successfully built twint fake-useragent googletransx\n",
            "Installing collected packages: multidict, frozenlist, yarl, urllib3, python-socks, asynctest, async-timeout, aiosignal, requests, pycares, elastic-transport, aiohttp, schedule, googletransx, fake-useragent, elasticsearch, dataclasses, cchardet, aiohttp-socks, aiodns, twint\n",
            "\u001b[33m  WARNING: The script twint is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\u001b[0m\n",
            "Successfully installed aiodns-3.0.0 aiohttp-3.8.1 aiohttp-socks-0.7.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 cchardet-2.1.7 dataclasses-0.6 elastic-transport-8.1.2 elasticsearch-8.2.0 fake-useragent-0.1.11 frozenlist-1.3.0 googletransx-2.4.2 multidict-6.0.2 pycares-4.1.2 python-socks-2.0.3 requests-2.27.1 schedule-1.1.0 twint-2.1.21 urllib3-1.26.9 yarl-1.7.2\n",
            "Collecting yake\n",
            "  Downloading yake-0.4.8-py2.py3-none-any.whl (60 kB)\n",
            "\u001b[K     |████████████████████████████████| 60 kB 3.0 MB/s \n",
            "\u001b[?25hCollecting segtok\n",
            "  Downloading segtok-1.5.11-py3-none-any.whl (24 kB)\n",
            "Collecting jellyfish\n",
            "  Downloading jellyfish-0.9.0.tar.gz (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 7.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from yake) (2.6.3)\n",
            "Requirement already satisfied: click>=6.0 in /usr/local/lib/python3.7/dist-packages (from yake) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from yake) (1.21.6)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from yake) (0.8.9)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from segtok->yake) (2019.12.20)\n",
            "Building wheels for collected packages: jellyfish\n",
            "  Building wheel for jellyfish (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jellyfish: filename=jellyfish-0.9.0-cp37-cp37m-linux_x86_64.whl size=74002 sha256=5067cdce38e965c5d2122b7252145418ab2b3b755c502f05c06625f311d86f06\n",
            "  Stored in directory: /root/.cache/pip/wheels/fe/99/4e/646ce766df0d070b0ef04db27aa11543e2767fda3075aec31b\n",
            "Successfully built jellyfish\n",
            "Installing collected packages: segtok, jellyfish, yake\n",
            "Successfully installed jellyfish-0.9.0 segtok-1.5.11 yake-0.4.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7mQXbs0eWgUM"
      },
      "outputs": [],
      "source": [
        "import twint\n",
        "import datetime\n",
        "import pandas as pd\n",
        "import dateutil.relativedelta\n",
        "import yake\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To read CSV keywords dataset from gdrive"
      ],
      "metadata": {
        "id": "dP1Kzzh-br1O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/NYUdataset/keywords-list - Sheet1.csv\")\n",
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7BN2fpDbnxf",
        "outputId": "f4336454-b6f9-467e-ce30-5bbf972d85c1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(84, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_KwList = df.rename(columns=df.iloc[0]).loc[1:]\n",
        "df_KwList.head(10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "rFxRNgwQb4Vv",
        "outputId": "cfee34de-8d78-4049-9704-21a6506af0e1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 Sinhala                     Tamil  \\\n",
              "1          මද්‍රසා පාසල්            மதரஸா பள்ளிகள்   \n",
              "2                  තම්බි                     தம்பி   \n",
              "3            ශරියා නීතිය              ஷரியா சட்டம்   \n",
              "4                 හම්බයො                         -   \n",
              "5   මාවනැල්ලෙ බුදු පිළිම  மாவனெல்ல புத்தர் சிலைகள்   \n",
              "6        පාස්කු ප්‍රහාරය          ஈஸ்டர் தாக்குதல்   \n",
              "7            මුස්ලිම් කඩ           முஸ்லீம் கடைகள்   \n",
              "8       ඉස්ලාම් අන්තවාදය       இஸ்லாமிய தீவிரவாதம்   \n",
              "9             කෝවිඩ් මරණ              கோவிட் மரணம்   \n",
              "10                ජිහාඩ්                    ஜிஹாத்   \n",
              "\n",
              "                               Translation in English  \n",
              "1                                     Madrasa Schools  \n",
              "2   Thambi - This is a derogative term in which Mu...  \n",
              "3                                        Shariya Laws  \n",
              "4   Hambayo - This is a derogative term in which M...  \n",
              "5                         Bhudha statues in Mawanella  \n",
              "6                                      Easter Attacks  \n",
              "7                                       Muuslim shops  \n",
              "8                                     Islam terrorism  \n",
              "9                                         Covid death  \n",
              "10                                             Jihaad  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-87ca2268-12d0-489d-ad0f-2f6ab6c606e8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sinhala</th>\n",
              "      <th>Tamil</th>\n",
              "      <th>Translation in English</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>මද්‍රසා පාසල්</td>\n",
              "      <td>மதரஸா பள்ளிகள்</td>\n",
              "      <td>Madrasa Schools</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>තම්බි</td>\n",
              "      <td>தம்பி</td>\n",
              "      <td>Thambi - This is a derogative term in which Mu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ශරියා නීතිය</td>\n",
              "      <td>ஷரியா சட்டம்</td>\n",
              "      <td>Shariya Laws</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>හම්බයො</td>\n",
              "      <td>-</td>\n",
              "      <td>Hambayo - This is a derogative term in which M...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>මාවනැල්ලෙ බුදු පිළිම</td>\n",
              "      <td>மாவனெல்ல புத்தர் சிலைகள்</td>\n",
              "      <td>Bhudha statues in Mawanella</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>පාස්කු ප්‍රහාරය</td>\n",
              "      <td>ஈஸ்டர் தாக்குதல்</td>\n",
              "      <td>Easter Attacks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>මුස්ලිම් කඩ</td>\n",
              "      <td>முஸ்லீம் கடைகள்</td>\n",
              "      <td>Muuslim shops</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>ඉස්ලාම් අන්තවාදය</td>\n",
              "      <td>இஸ்லாமிய தீவிரவாதம்</td>\n",
              "      <td>Islam terrorism</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>කෝවිඩ් මරණ</td>\n",
              "      <td>கோவிட் மரணம்</td>\n",
              "      <td>Covid death</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>ජිහාඩ්</td>\n",
              "      <td>ஜிஹாத்</td>\n",
              "      <td>Jihaad</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-87ca2268-12d0-489d-ad0f-2f6ab6c606e8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-87ca2268-12d0-489d-ad0f-2f6ab6c606e8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-87ca2268-12d0-489d-ad0f-2f6ab6c606e8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_KwList['Tamil'][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "FjdwxR2nfham",
        "outputId": "950e34e3-33eb-4acc-cb42-03e96547bac8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'மதரஸா பள்ளிகள்'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set the parameters needed for the keyword extractor\n",
        "kw_extractor = yake.KeywordExtractor()\n",
        "custom_kw_extractor = yake.KeywordExtractor(lan='en', n=3, dedupLim=0.1, top=3, features=None)\n",
        "!pip install nest_asyncio\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5vroTC0kdS7",
        "outputId": "8f6d0520-ca6a-486e-8bdd-40920f208507"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.7/dist-packages (1.5.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "e-G3sKowh-8f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "directory = '/content/drive/MyDrive/NYUdataset/twitter/' \n",
        "keywords = custom_kw_extractor.extract_keywords('ශරියා නීතිය')\n",
        "first_tuple_elements = [a_tuple[0] for a_tuple in keywords]\n",
        "search_query = ' OR '.join(first_tuple_elements)\n",
        "    # configuration for twitter\n",
        "config = twint.Config()\n",
        "config.Search = str(search_query)\n",
        "config.Limit = 2500\n",
        "config.Since = \"2021-01-01 00:00:00\"\n",
        "#config.Until = \"2021–01–01\"\n",
        "config.Filter_retweets = True\n",
        "config.Store_csv = True\n",
        "config.Output = 'ශරියා නීතිය_kw_tweets' + '.csv'\n",
        "\n",
        "    # run twitter search and save the .csv file\n",
        "twint.run.Search(config)"
      ],
      "metadata": {
        "id": "hRkcEczwlI6U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc8a9a4b-3ea2-4803-ec33-b255716706fb"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1510579903409754112 2022-04-03 11:28:08 +0000 <EChamara1> ඇෆ්ගනිස්ථානය එරට පොපි මල් වගාව සම්පූර්ණයෙන්ම තහනම් කරයි එරට අවනත නොවන පුද්ගලයන්ට එරෙහිව ශරියා නීතිය ක්‍රියාත්මක කරන බව ඔවුන් පවසයි\n",
            "1487128916800294915 2022-01-28 18:22:17 +0000 <nirowa74> ''ප්‍රජාතන්ත්‍රවාදය'' අහෝසි කර 'ශරියා' නීතිය ද ???  🙄  ''ශරියා නීතිය යනු රටේ නීතිය අභිබවා යන්නා වූ  තවත් ම්ලේචඡ නීති පද්ධතියකි'' - උපුටා 🧐  දන්නවා ද 'ඔය සම-හරක් නිෂ්ශබ්දව ඉන්නතාක්  තමුන්ගේ කේප්ප කම ප්‍රදර්ශනය නොවනු ඇත කියා'  පැරණි කියමනකුත් තියෙනවා 🤔\n",
            "1467028889432375298 2021-12-04 07:11:57 +0000 <MaheshNegombo> රිසානාව සෞදියේදි ශරියා නීතියට අනුව මරපු වෙලාවේ උනත් අපේ මුස්ලිම් ප්‍රජාව ඒක නිකන් හරි දැක්ක නොදැක්ක් වගේ හිටියා.. පාර්ලිමේන්තුවේ පවා රන්ජන් ඒ ගැන කතා කරද්දී ඒ මන්ත්‍රීවරු කිව්වේ ඒක දේව නීතිය වගේ කතාවක්..   පාකිස්තාන සිද්දියේදි උනත් කවුරුහරි එහෙම හැසිරෙනවනම් එතන අවුලක් තියනව.\n",
            "1466971279005650946 2021-12-04 03:23:02 +0000 <t_saliya> @MajorPoonia @irajonline #iraj #Pakistan මේ තමයි සැබැ මුස්ලිම් ආගමික නීතිය. මෙය ලෝකය පුරා පැතිර යන්නේ වෛරසයකටත් වඩා වැඩි වේගයෙන්. දැන්වත් ලංකාවේ ශරියා නීතිය සහ ඒවා උගන්වන පුද්ගලයන් සහ මද්‍රාස් පාසැල් තහනම් කල යුතුමයි. නැතිනම් හෙට නුඔගේ දුව පුතා ලංකාවේ පාරක පිලිස්සී මිය යනු ඇත. @t_saliya @irajonline\n",
            "1458078900030935044 2021-11-09 14:27:54 +0000 <unknown_lankan> ඔක්කොම ලේ රෝහලේ විතරක් නෙවේ. ගෝටාබය ආවා විතරයි වද පෙති නෑ ප්ලාස්ටික් හාල් නෑ මුස්ලිම් පල්ලිවල කඩු නෑ ශරියා නීතිය නෑ හලාල් වර්ජන නෑ වද සැත්කම් නෑ බලන්න රට කොච්චර සාමකාමී උනාද කියලා\n",
            "1452171760212721669 2021-10-24 07:15:02 +0000 <choiefopeipe> @chaturaalwis ශරියා නීතිය, හලාල් පේන්න බැරිවුන සිංහලේ රාවණාගෙ යක්ඛ පුතුන් පාස්පෝට් පොලීමේ පොරකනව මැද පෙරදිග යන්න.🙉😂\n",
            "1448844312461017099 2021-10-15 02:52:56 +0000 <LBndara> @adaderanasin බලාගෙන ඉන්නේ තවත් ශරියා නීතිය මුන් ඉල්ලනවනම් මුන්ගෙන්ම පටන් ගන්න\n",
            "1432988312113876996 2021-09-01 08:46:51 +0000 <lemon_lo3> තලේබාන්වරුන්ගේ ඉස්ලාමය හා ශරියා නීතිය හමුවේ අන්‍ත අසරණ වන්නෙ ඇෆ්ගන් කාන්තාව ය.  https://t.co/HimAAZKZPA\n",
            "1429273561936584711 2021-08-22 02:45:46 +0000 <Wind_Desika> ඔක්කොම ලේ රෝහලේ විතරක් නෙවේ. ගෝටාබය ආවා විතරයි වද පෙති නෑ ප්ලාස්ටික් හාල් නෑ මුස්ලිම් පල්ලිවල කඩු නෑ ශරියා නීතිය නෑ හලාල් වර්ජන නෑ වද සැත්කම් නෑ බලන්න රට කොච්චර සාමකාමී උනාද කියලා\n",
            "1428743573361422338 2021-08-20 15:39:47 +0000 <DilruNiro> @Cheesequeen324 එයාලා කියන විදියට ඉන්නෝන. නැත්තම් ශරියා නීතිය. 😒\n",
            "1427612193730686977 2021-08-17 12:44:05 +0000 <EChamara1> තවත් රටක අය ශරියා නීතිය ඉල්ලද්දී ඒ නිතියට බියෙන් පැන යන ඇෆ්ගන් වැසියන්  https://t.co/aWZwCgrDdi\n",
            "1427571499993423872 2021-08-17 10:02:23 +0000 <IamIsPra> @Sedona_B @Anjana_____ 2013 කරපු survey report එකක් තියනවා, ඇෆ්ගනිස්ථානේ මිනිස්සුන්ගෙන් 99%ක් ශරියා නීතිය ඇෆ්ගනිස්ථානේ ස්ථාපනය වෙනවට කැමතියි කියලා. එක්කෝ ඔය පැනලා යන්නෙ ඉතිරි 1%. එහෙමත් නැත්තන් කාලයත් එක්ක ශරියා එපා වෙලා. ඒත් නැත්තන් ඉල්ලුවට දුන්නම ක්‍රියාත්මක වෙලා නිදහස නැතිවෙයි කියලා බයවෙලා.\n",
            "1427252449526489091 2021-08-16 12:54:35 +0000 <DonOutcast> @CoolBoySafa @TheCitizen1 @Sudumameduvada ශරියා නීතිය හැදුවෙත් මිනිස්සු තමයි. ඕක ඒ කාලෙ ඉඳන්ම ප්‍රශ්නයක් තමා. ඒ කාලෙ ඒවාට තිබුණ විර්දධත්වය ඉස්මතු වණේ නෑ. එහෙම අදහස් යටපත් කරන්න ලේසියි හුදකලාභාවය නිසාම. එච්චරයි. ඒවා අදත් ගෝත්‍රිකයි. අදත් ගෝත්‍රිකයි.\n",
            "1427167545942028288 2021-08-16 07:17:13 +0000 <TechNewsLK1> @TheCitizen1 තලේබාන්, ISIS ශරියා නීතිය කියන්නේ අපේ රජකාලේ නීතිය වෙගේ. ඩුබායි වලත් ශරියා නීතිය ක්‍රියාත්මකයි. ඒත් ශරියා නීතියේ යම් යම් දේවල් ක්‍රියාත්මක කරන්නේ නෑ. ඒ වෙනුවට දඩ හා සිර දඬුවම් දෙනවා. ගල් ගැසීම, අතපය කැපීම, හිස ගසා දැමීම තලේබාන්, ISIS කරාට ගොඩක් මුස්ලිම් රටවල් එහෙම අන්තවාදී නෑ.\n",
            "1421132847092482049 2021-07-30 15:37:28 +0000 <Mohamme58747629> @Sharkzen1 @optimuspnj අල්ලාහ් සිටින තෙක් අපි නොබියව ඉදිරියට යමු. වද.සිංහලයන්ගේද බීමත් සිංහලය්න්ගේද කල් ක්‍රියාව තව පරම්පරා තුනකින් අවසන් වේ.  ඉන් පසු අල්ලාහ් සහ ශරියා නීතිය මගින් ශිරි ලංකාව පාලනය කෙරෙනු ඇත. ඉවසිලිමත් වන්න අසිරිමිත සෙනෙහෙවන්ත වූද අපිරිමිත කරුණාවන්ත වූද අල්ලහ් ගේ වචනයයි .\n",
            "1419505560735686658 2021-07-26 03:51:13 +0000 <slppofficial> ශරියා නීතිය මෙරටට ගෙන එන්න සජිත් පිලෙන් යෝජනාවක්  https://t.co/31bOgaz3ss\n",
            "1419477348877889538 2021-07-26 01:59:07 +0000 <asianmirrorsin> ශරියා නීතිය මෙරටට ගෙන එන්න සජිත් පිලෙන් යෝජනාවක්  https://t.co/MRhDWlllEd  https://t.co/yLk9V8LUdW\n",
            "1419109825271635969 2021-07-25 01:38:42 +0000 <Lockdownbrat> @DJSlash9 බැහැනේ..ලංකාවේ ශරියා නීතිය ක්‍රියාත්මක කරන්න දෙන්න බෑ නේ.\n",
            "1361331117475856387 2021-02-15 15:06:45 +0000 <KMeeeaaow> @NewsWireLK උඩරට විවාහ නීතිය, තේවසෙලමෛ නීතිය කිසිම ආකාරයකින් ශරියා නීතියට ගැලපෙන්නේ නැහැ. මොකද අර නීති ලංකාවේ සංස්කෘතියට එකගයි. ශරියා නීති ගැන ප්‍රජාව අතරින් ඇවිත් කතිකාවක් කරගෙන ඕන සම්මත කරන්න. මේක විවාහයකින් නෙමෙයි විනාශයකින් කෙළවර වෙන වැඩක්.. #මතය\n",
            "1355887451089350661 2021-01-31 14:35:34 +0000 <KOTTANOFFICIAL> @DharmicPhoenix අනිවා. ශරියා නොවෙයී, යම රජ්ජුරුවන්ගේ නීතිය මෙහේ ආවත් නිසි ලෙස ක්‍රියාත්මක වීම හීනයක් විතරයී.\n",
            "[!] No more data! Scraping will stop now.\n",
            "found 0 deleted tweets in this search.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(df_KwList),1):\n",
        "    # create a unique identifier for the directory\n",
        "    directory = '/content/drive/MyDrive/NYUdataset/twitter/' \n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "    # create output file name\n",
        "    output_name = directory + 'TamilKW_'+df_KwList['Sinhala'][i]\n",
        "    keywords = custom_kw_extractor.extract_keywords(df_KwList['Sinhala'][i])\n",
        "    first_tuple_elements = [a_tuple[0] for a_tuple in keywords]\n",
        "    search_query = ' OR '.join(first_tuple_elements)\n",
        "    # configuration for twitter\n",
        "    config = twint.Config()\n",
        "    config.Search = str(search_query)\n",
        "    config.Limit = 2500\n",
        "    #config.Since = \"2021-01-01 00:00:00\"\n",
        "    #config.Until = \"2021–12–31\"\n",
        "    config.Filter_retweets = True\n",
        "    config.Store_csv = True\n",
        "    config.Output = output_name + '.csv'\n",
        "\n",
        "    # run twitter search and save the .csv file\n",
        "    twint.run.Search(config)"
      ],
      "metadata": {
        "id": "XF7BZkpNXnMf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}