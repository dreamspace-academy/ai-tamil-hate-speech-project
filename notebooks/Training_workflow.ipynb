{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2i_sDNxi1mSr"
      },
      "source": [
        "# Training workflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfnFw-1V1n6K"
      },
      "source": [
        "## Install necessary libraries for loading repo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Usbkfzv3FNkb"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install dvc fastds\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTN0bclB10OD"
      },
      "source": [
        "## Set all credentials and download all necessary files/data for training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjLbZTpg8ZTj"
      },
      "source": [
        "### Set up local repo and branch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZ_mzvWzsdrO"
      },
      "outputs": [],
      "source": [
        "# Clone repo with personal token (Settings -> Tokens -> Default Access Token)\n",
        "!git clone https://{token}@dagshub.com/Omdena/NYU.git\n",
        "%cd NYU\n",
        "\n",
        "# Switch to branch you want to work with and sync with remote branch (if necessary)\n",
        "!git fetch origin\n",
        "#!git checkout -b cross-validation origin/cross-validation\n",
        "\n",
        "# Change directory to training workflow\n",
        "%cd tasks/task-4-language-transformer-models/workflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgaX4bX0CIAV"
      },
      "source": [
        "### Set up DVC and git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YYZJTlVTn1Dp"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "dvc remote add origin --local https://dagshub.com/Omdena/NYU.dvc\n",
        "dvc remote modify --local origin auth basic\n",
        "dvc remote modify --local origin user {user}\n",
        "dvc remote modify --local origin password {token}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eIpfRrxpoJ2X"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "git config --global user.email \"{user}@gmail.com\"\n",
        "git config --global user.name \"{user}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMDKIF7-v9oI"
      },
      "source": [
        "### Set mlflow credentials as env variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J19J2M_Xv9uh"
      },
      "outputs": [],
      "source": [
        "%env MLFLOW_TRACKING_USERNAME={user}\n",
        "%env MLFLOW_TRACKING_PASSWORD={token}\n",
        "%env MLFLOW_TRACKING_URI=https://dagshub.com/Omdena/NYU.mlflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1Eqzw9lCTCO"
      },
      "source": [
        "### Pull training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IidgFZzjqLsJ"
      },
      "outputs": [],
      "source": [
        "!dvc pull -r origin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MruZrX3iWM0f"
      },
      "outputs": [],
      "source": [
        "!dvc pull -r origin -R ../data/train.csv ../data/test.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gRW8ysW94sG"
      },
      "source": [
        "### Install dependencies for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ncDfHYj_9SDa"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9rtzrkC7yBv"
      },
      "source": [
        "## Making changes to code only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBLMW_AW7yLe"
      },
      "outputs": [],
      "source": [
        "!git status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnGEypRx8Rnp"
      },
      "outputs": [],
      "source": [
        "!git add train_k_fold.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjabtJZQ8UWo"
      },
      "outputs": [],
      "source": [
        "!git commit -m \"Update training code\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o9A-f_c38YJH"
      },
      "outputs": [],
      "source": [
        "!git push"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6qcnPwVzqOw"
      },
      "source": [
        "## Data processing pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kTIkOjefakZt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IjgRjP2YMYwR"
      },
      "outputs": [],
      "source": [
        "file_names = [\n",
        "    \"/content/1-100-positives-og.csv\",\n",
        "    \"/content/2-100-positives-og.csv\",\n",
        "    \"/content/3-100-positives-og.csv\",\n",
        "    \"/content/4-561-positives.csv\"\n",
        "]\n",
        "df_data = []\n",
        "\n",
        "for filename in file_names:\n",
        "    df = pd.read_csv(filename, index_col=None, header=0, sep=\",\")\n",
        "    df_data.append(df)\n",
        "\n",
        "data_positive = pd.concat(df_data, axis=0, ignore_index=True)\n",
        "data_positive.rename(columns = {'sample':'text', 'category': 'label'}, inplace = True)\n",
        "data_positive.dropna(axis=0, how=\"any\", inplace=True)\n",
        "data_positive['label'] = 'Hate-Speech'\n",
        "\n",
        "print(f\"Dreamspace annotated positives: {data_positive.shape[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JAEcK36qNUGj"
      },
      "outputs": [],
      "source": [
        "data_negative = pd.read_csv(\"/content/1-366-negatives.csv\", index_col=None, header=0)\n",
        "data_negative.rename(columns = {'sample':'text', 'category': 'label'}, inplace = True)\n",
        "data_negative.dropna(axis=0, how=\"any\", inplace=True)\n",
        "data_negative['label'] = 'Non-Hate-Speech'\n",
        "\n",
        "print(f\"Dreamspace annotated negatives: {data_negative.shape[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tajGRs7tONK-"
      },
      "outputs": [],
      "source": [
        "data_validation = pd.read_csv(\"/content/validation-set.csv\", index_col=None, header=0)\n",
        "data_validation.rename(columns = {'sample':'text'}, inplace = True)\n",
        "data_validation['label'] = data_validation['label'].map(lambda x: 'Hate-Speech' if x == 'positive' else 'Non-Hate-Speech')\n",
        "\n",
        "print(f\"Dreamspace valdation positives: {data_validation.label.value_counts()[1]} ({data_validation.label.value_counts(normalize=True)[1]*100 :.2f}%)\")\n",
        "print(f\"Dreamspace valdation negatives: {data_validation.label.value_counts()[0]} ({data_validation.label.value_counts(normalize=True)[0]*100 :.2f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZ6tpNl5Oaq-"
      },
      "outputs": [],
      "source": [
        "data_docano = pd.read_csv(\"/content/doccano_annotated.csv\", index_col=0, header=0)\n",
        "data_docano['label'] = data_docano['label'].map(lambda x: 'Hate-Speech' if x == 'Positive' else 'Non-Hate-Speech')\n",
        "\n",
        "print(f\"Task 2 annotated positives: {data_docano.label.value_counts()[1]} ({data_docano.label.value_counts(normalize=True)[1]*100 :.2f}%)\")\n",
        "print(f\"Task 2 annotated negatives: {data_docano.label.value_counts()[0]} ({data_docano.label.value_counts(normalize=True)[0]*100 :.2f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VI9zqI9MPdkz"
      },
      "outputs": [],
      "source": [
        "data_homophobia = pd.read_csv(\"/content/hate-speech-homophobia.csv\", index_col=0, header=0)\n",
        "\n",
        "print(f\"homophobia dataset positives: {data_homophobia.label.value_counts()[1]} ({data_homophobia.label.value_counts(normalize=True)[1]*100 :.2f}%)\")\n",
        "print(f\"homophobia dataset negatives: {data_homophobia.label.value_counts()[0]} ({data_homophobia.label.value_counts(normalize=True)[0]*100 :.2f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XBZVbLpaz6_"
      },
      "source": [
        "For the test set, we consider the provided validation set and a small sample of the other datasets, given that the different datasets focus on different topics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VfDepUHabtJR"
      },
      "outputs": [],
      "source": [
        "train_homophobia, test_homophobia = train_test_split(\n",
        "    data_homophobia,\n",
        "    test_size=0.05,\n",
        "    random_state=1,\n",
        "    stratify=data_homophobia.label\n",
        ")\n",
        "\n",
        "train_docano, test_docano = train_test_split(\n",
        "    data_docano,\n",
        "    test_size=0.05,\n",
        "    random_state=1,\n",
        "    stratify=data_docano.label\n",
        ")\n",
        "\n",
        "train_positive, test_positive = train_test_split(\n",
        "    data_positive,\n",
        "    test_size=0.1,\n",
        "    random_state=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x__SCF-Eero0"
      },
      "outputs": [],
      "source": [
        "all_test = pd.concat([test_homophobia, test_docano, test_positive, data_negative, data_validation], axis=0, ignore_index=True)\n",
        "test_counts = all_test.label.value_counts(normalize=True)\n",
        "print(f\"Test positives: {all_test.shape[0]*test_counts[1]} ({test_counts[1]*100 :.2f})\")\n",
        "print(f\"Test negatives: {all_test.shape[0]*test_counts[0]} ({test_counts[0]*100 :.2f})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5p1zSghhQ-J"
      },
      "outputs": [],
      "source": [
        "all_train = pd.concat([train_homophobia, train_docano, train_positive], axis=0, ignore_index=True)\n",
        "train_counts = all_train.label.value_counts(normalize=True)\n",
        "print(f\"Train positives: {all_train.shape[0]*train_counts[1]} ({train_counts[1]*100 :.2f})\")\n",
        "print(f\"Train negatives: {all_train.shape[0]*train_counts[0]} ({train_counts[0]*100 :.2f})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fVGPsAPGiW2c"
      },
      "outputs": [],
      "source": [
        "all_test.to_csv(\"/content/NYU/tasks/task-4-language-transformer-models/data/test.csv\")\n",
        "all_train.to_csv(\"/content/NYU/tasks/task-4-language-transformer-models/data/train.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NaZ8vNRclhix"
      },
      "outputs": [],
      "source": [
        "!dvc status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJqBohA9lkAg"
      },
      "outputs": [],
      "source": [
        "!dvc add ../data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYyOEt47l1hq"
      },
      "outputs": [],
      "source": [
        "!git status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70XU-uXfl24X"
      },
      "outputs": [],
      "source": [
        "!git add ../data.dvc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6rSuZprhl6OL"
      },
      "outputs": [],
      "source": [
        "!git commit -m \"Update datasets\"\n",
        "!git push"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPlX4Ww9lo7A"
      },
      "outputs": [],
      "source": [
        "!dvc push -r origin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Phoo_gBq83KZ"
      },
      "source": [
        "## Create cross validation pipeline (*This should be run only if there's a change in the pipeline that we want to update in DagsHub*)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGoSbizy2nyn"
      },
      "source": [
        "Takes all data and creates k folds to train model and give confidence interval on performance metrics. No trained model is saved since cross-validation is intended for picking best configuration only."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2PkPjh72xJX4"
      },
      "outputs": [],
      "source": [
        "# Create branch\n",
        "!git checkout -b cross-validation origin/cross-validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0WTMrZez_0T"
      },
      "outputs": [],
      "source": [
        "!dvc run -n train_k_fold \\\n",
        "-d ../data/train.csv \\\n",
        "-d train_k_fold.py \\\n",
        "-p params.yaml: \\\n",
        "-m model_artifacts/cv_results.json \\\n",
        "-o model_artifacts/args.pt \\\n",
        "-o model_artifacts/logfile.log \\\n",
        "--force \\\n",
        "--no-run-cache \\\n",
        "python train_k_fold.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git status"
      ],
      "metadata": {
        "id": "7QE3Mn5f2_Qb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FRV8CdAV4QPu"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "git status\n",
        "git add dvc.lock\n",
        "git commit -m \"Update k stratified cross validation training pipeline\"\n",
        "git push\n",
        "dvc push -r origin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c159tM62rrp9"
      },
      "source": [
        "## Create pipeline for train-dev procedure (*This should be run only if there's a change in the pipeline that we want to update in DagsHub*)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJB4ded8yg6N"
      },
      "outputs": [],
      "source": [
        "%cd /content/NYU/tasks/task-4-language-transformer-models/workflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1itgh3iR3ci7"
      },
      "source": [
        "Best model on dev set is saved and compute metrics of this model on test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ICAe24yg-H2p"
      },
      "outputs": [],
      "source": [
        "!dvc run -n train_eval \\\n",
        "-d ../data/train.csv \\\n",
        "-p params.yaml: \\\n",
        "-d train_eval.py \\\n",
        "-o model_artifacts/model_best.pt \\\n",
        "-o model_artifacts/args.pt \\\n",
        "-o model_artifacts/test_labels.txt \\\n",
        "-o model_artifacts/test_labels_gold.txt \\\n",
        "-o model_artifacts/test_labels_pred.txt \\\n",
        "-o model_artifacts/test_labels_prob_pred.txt \\\n",
        "-m model_artifacts/test_pr_values.csv \\\n",
        "--force \\\n",
        "--no-run-cache \\\n",
        "python train_eval.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm ./../../../.dvc/tmp/rwlock"
      ],
      "metadata": {
        "id": "GFOQpvJkQPvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lIIsctYr3_iL"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "git status\n",
        "git add train_eval.py params.yaml dvc.lock\n",
        "git commit -m \"Update training pipeline\"\n",
        "git push\n",
        "dvc push -r origin"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create pipeline for test procedure (This should be run only if there's a change in the pipeline that we want to update in DagsHub)"
      ],
      "metadata": {
        "id": "W8hUUVr3TUDQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!dvc run -n test \\\n",
        "-d ../data/test.csv \\\n",
        "-d test.py \\\n",
        "-d model_artifacts/model_best.pt \\\n",
        "-d model_artifacts/args.pt \\\n",
        "-m test_results/test_metrics.json \\\n",
        "--force \\\n",
        "--no-run-cache \\\n",
        "python test.py"
      ],
      "metadata": {
        "id": "n1QQACq1TWkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git status"
      ],
      "metadata": {
        "id": "-TOJxO1AdPXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "git status\n",
        "git add dvc.lock dvc.yaml est_results/.gitignore\n",
        "git commit -m \"Update training pipeline\"\n",
        "git push\n",
        "dvc push -r origin"
      ],
      "metadata": {
        "id": "0j6j5ToPdCuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eZDcF32-HvG"
      },
      "source": [
        "## Run workflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyhpetDY-nBe"
      },
      "source": [
        "Modify `params.yaml` file to tune hyperparams and training arguments as needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2dlJgYACuaW"
      },
      "outputs": [],
      "source": [
        "!dvc repro"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git status"
      ],
      "metadata": {
        "id": "JWddcCy4ksGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6bMAIYe7WZ9"
      },
      "source": [
        "Save changes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hgiq9OBi7Y1K"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "git add ../data.dvc dvc.lock params.yaml\n",
        "git commit -m \"Update pipeline for binary classification\"\n",
        "git push"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHN6DJ6n7YKD"
      },
      "outputs": [],
      "source": [
        "!dvc push -r origin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ub9P3FyUwm9F"
      },
      "source": [
        "## Deleting pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YeD2exBUwnHG"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "dvc remove train_k_fold\n",
        "git add .gitignore dvc.lock dvc.yaml\n",
        "git commit -m \"Remove cross-validation pipeline\"\n",
        "git push"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Training_workflow.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}